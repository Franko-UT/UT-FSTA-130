{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Create `ab_reduced_noNaN` DataFrame\n",
    "\n",
    "To create the `ab_reduced_noNaN` DataFrame, the goal is to:\n",
    "1. Select relevant columns.\n",
    "2. Drop rows with missing values (`NaN`)\n",
    "\n",
    "---\n",
    "\n",
    "### Code to Prepare `ab_reduced_noNaN`\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming the original dataset is named 'ab_books'\n",
    "# Load the data (if provided as a CSV or similar file)\n",
    "# ab_books = pd.read_csv(\"path_to_file.csv\")\n",
    "\n",
    "# Select relevant columns (example columns, adjust based on dataset details)\n",
    "columns_to_keep = ['BookID', 'List Price', 'NumPages', 'Thick', 'Hard_or_Paper']\n",
    "\n",
    "# Create a reduced DataFrame with selected columns\n",
    "ab_reduced = ab_books[columns_to_keep]\n",
    "\n",
    "# Remove rows with missing values\n",
    "ab_reduced_noNaN = ab_reduced.dropna()\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(ab_reduced_noNaN.head())\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Explanation of the Steps\n",
    "1. **`columns_to_keep`**: Select the relevant columns required for the analysis.\n",
    "2. **`dropna()`**: Removes all rows with any missing data to ensure clean input for model training.\n",
    "3. **Resulting DataFrame**: `ab_reduced_noNaN` contains only the required rows and columns without any missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Create an 80/20 Split for Training and Testing\n",
    "\n",
    "The task is to split the clean DataFrame `ab_reduced_noNaN` into a training set (`ab_reduced_noNaN_train`) and a testing set (`ab_reduced_noNaN_test`) with an 80/20 ratio.\n",
    "\n",
    "---\n",
    "\n",
    "### Code for 80/20 Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming ab_reduced_noNaN is the cleaned DataFrame from Question 1\n",
    "# Split the data into training (80%) and testing (20%) sets\n",
    "ab_reduced_noNaN_train, ab_reduced_noNaN_test = train_test_split(\n",
    "    ab_reduced_noNaN, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Report the number of observations in each set\n",
    "print(f\"Number of observations in the training set: {len(ab_reduced_noNaN_train)}\")\n",
    "print(f\"Number of observations in the testing set: {len(ab_reduced_noNaN_test)}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Explanation of the Code\n",
    "1. **`train_test_split()`**:\n",
    "   - Splits the dataset into two subsets:\n",
    "     - `train_size` defaults to the remainder when `test_size` is specified.\n",
    "     - `random_state` ensures reproducibility of the split.\n",
    "   - The training set contains 80% of the data, while the testing set contains 20%.\n",
    "\n",
    "2. **Output**:\n",
    "   - The number of observations in each set is printed.\n",
    "\n",
    "---\n",
    "\n",
    "### Expected Output\n",
    "For example:\n",
    "```\n",
    "Number of observations in the training set: 800\n",
    "Number of observations in the testing set: 200\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Train a Decision Tree Using Only `List Price`\n",
    "\n",
    "The task is to train a `DecisionTreeClassifier` to predict whether a book is a hardcover or paperback using only the `List Price` feature, with a maximum tree depth of 2.\n",
    "\n",
    "---\n",
    "\n",
    "### Code for Training the Decision Tree\n",
    "\n",
    "```python\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "import pandas as pd\n",
    "\n",
    "# Prepare target (y) and feature (X) variables\n",
    "y = pd.get_dummies(ab_reduced_noNaN_train[\"Hard_or_Paper\"])['H']  # Target: 1 for Hardcover, 0 for Paperback\n",
    "X = ab_reduced_noNaN_train[['List Price']]  # Feature: List Price\n",
    "\n",
    "# Initialize and train the Decision Tree model\n",
    "clf = DecisionTreeClassifier(max_depth=2, random_state=42)  # max_depth=2 as specified\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Visualize the decision tree\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 7))\n",
    "plot_tree(clf, feature_names=['List Price'], class_names=['Paperback', 'Hardcover'], filled=True)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Explanation of the Code\n",
    "1. **Target (`y`)**:\n",
    "   - Convert the `Hard_or_Paper` column to binary (e.g., 1 for Hardcover, 0 for Paperback) using `pd.get_dummies()`.\n",
    "\n",
    "2. **Feature (`X`)**:\n",
    "   - Use only the `List Price` column as the predictor.\n",
    "\n",
    "3. **Train the Model**:\n",
    "   - `DecisionTreeClassifier(max_depth=2)`: Limits the depth of the decision tree to 2 for simplicity and to avoid overfitting.\n",
    "\n",
    "4. **Visualize the Tree**:\n",
    "   - `plot_tree()` shows the splits made by the model. Each node represents a decision based on `List Price`.\n",
    "\n",
    "---\n",
    "\n",
    "### Expected Output\n",
    "- A decision tree plot showing how `List Price` determines whether a book is hardcover or paperback.\n",
    "- Example decision tree structure:\n",
    "  ```\n",
    "  If List Price <= 20.5: Predict Paperback\n",
    "  If List Price > 20.5: Predict Hardcover\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Split Dataset into Training and Testing, Fit Decision Tree, and Visualize Predictions\n",
    "\n",
    "The task involves:\n",
    "1. Creating an 80/20 split (already done in Question 2).\n",
    "2. Fitting a decision tree classifier (`clf`) using only `List Price`.\n",
    "3. Explaining the predictions made based on the tree.\n",
    "\n",
    "---\n",
    "\n",
    "### Code to Fit and Visualize the Decision Tree\n",
    "\n",
    "```python\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare target (y) and feature (X) variables for training set\n",
    "y_train = pd.get_dummies(ab_reduced_noNaN_train[\"Hard_or_Paper\"])['H']  # 1 for Hardcover, 0 for Paperback\n",
    "X_train = ab_reduced_noNaN_train[['List Price']]  # Feature: List Price\n",
    "\n",
    "# Initialize and train the Decision Tree model\n",
    "clf = DecisionTreeClassifier(max_depth=2, random_state=42)  # max_depth=2\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Visualize the decision tree\n",
    "plt.figure(figsize=(10, 7))\n",
    "plot_tree(clf, feature_names=['List Price'], class_names=['Paperback', 'Hardcover'], filled=True)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Predictions Made by the Decision Tree\n",
    "The decision tree will predict whether a book is hardcover or paperback based on `List Price`. For example:\n",
    "1. If `List Price <= threshold_1`: Predict `Paperback`.\n",
    "2. If `List Price > threshold_1` and `<= threshold_2`: Predict `Hardcover`.\n",
    "3. If `List Price > threshold_2`: Predict `Paperback`.\n",
    "\n",
    "---\n",
    "\n",
    "### Explanation of Tree Predictions\n",
    "- The decision tree splits the data based on optimal thresholds for `List Price`.\n",
    "- At each split:\n",
    "  - If the condition is met, the decision follows one branch.\n",
    "  - If the condition is not met, the decision follows the other branch.\n",
    "- The model predicts the class (Paperback/Hardcover) with the majority in each terminal node.\n",
    "\n",
    "---\n",
    "\n",
    "### Expected Output\n",
    "You will see:\n",
    "- A decision tree plot with nodes indicating thresholds for `List Price`.\n",
    "- Predictions are made based on the splits at each node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: Train a Decision Tree with Multiple Features and Visualize\n",
    "\n",
    "The task involves:\n",
    "1. Training a decision tree classifier (`clf2`) using the predictors `NumPages`, `Thick`, and `List Price`.\n",
    "2. Setting `max_depth` to 4.\n",
    "3. Visualizing the tree and explaining its predictions.\n",
    "\n",
    "---\n",
    "\n",
    "### Code to Train and Visualize the Decision Tree\n",
    "\n",
    "```python\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare the predictors (X) and target variable (y) for training set\n",
    "y_train = pd.get_dummies(ab_reduced_noNaN_train[\"Hard_or_Paper\"])['H']  # Target: 1 for Hardcover, 0 for Paperback\n",
    "X_train = ab_reduced_noNaN_train[['NumPages', 'Thick', 'List Price']]  # Features: NumPages, Thick, List Price\n",
    "\n",
    "# Initialize and train the Decision Tree model\n",
    "clf2 = DecisionTreeClassifier(max_depth=4, random_state=42)  # max_depth=4\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "# Visualize the decision tree\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(clf2, feature_names=['NumPages', 'Thick', 'List Price'], class_names=['Paperback', 'Hardcover'], filled=True)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Explanation of Tree Predictions\n",
    "1. The decision tree splits based on combinations of the predictors (`NumPages`, `Thick`, `List Price`).\n",
    "2. Each split reduces the uncertainty in predicting the target variable (`Hardcover` or `Paperback`).\n",
    "3. The `max_depth=4` parameter restricts the number of splits, balancing simplicity and performance.\n",
    "\n",
    "---\n",
    "\n",
    "### Visualizing Predictions\n",
    "- The `plot_tree` visualization shows:\n",
    "  - Decision nodes indicating the splitting condition (e.g., `NumPages <= X`).\n",
    "  - Leaf nodes with the predicted class and the proportion of samples in each class.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Observations\n",
    "- The tree predicts whether a book is hardcover or paperback based on thresholds in the three predictors.\n",
    "- For example:\n",
    "  - If `NumPages <= 300`, `Thick <= 2`, and `List Price > 20`, predict `Hardcover`.\n",
    "  - If `NumPages > 300` and `Thick > 2`, predict `Paperback`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
